{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97a9e4e0",
   "metadata": {},
   "source": [
    "# 讀取資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c2ec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# 讀取所有圖片檔案和標註檔案\n",
    "def load_data_from_directory(directory_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # 讀取資料夾中的所有圖片和標註檔案\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            image_path = os.path.join(directory_path, filename)\n",
    "            label_path = os.path.join(directory_path, filename.replace(\".jpg\", \".txt\"))\n",
    "            \n",
    "            # 讀取圖片\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # 轉換為RGB格式\n",
    "            \n",
    "            # 讀取標註\n",
    "            with open(label_path, 'r') as label_file:\n",
    "                coords = []\n",
    "                for line in label_file.readlines():\n",
    "                    parts = line.split()\n",
    "                    x_min, y_min, width, height = map(float, parts[1:])\n",
    "                    coords.append([x_min, y_min, width, height])\n",
    "                coords = np.array(coords)\n",
    "            \n",
    "            # 儲存圖片和標註\n",
    "            images.append(image)\n",
    "            labels.append(coords)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "# 讀取資料\n",
    "directory_path = r'C:\\Users\\AaronWu\\Documents\\GitHub\\python-\\Smart_drone_hw\\pineapple\\autoencoder\\labeled'  # 替換為實際的資料夾路徑\n",
    "images, labels = load_data_from_directory(directory_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e6b625",
   "metadata": {},
   "source": [
    "# 切分訓練資料與測試資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4f8318",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 將資料分為訓練資料和測試資料\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"訓練資料數量：{len(X_train)}\")\n",
    "print(f\"測試資料數量：{len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283ea246",
   "metadata": {},
   "source": [
    "# 處理資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e419c8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "# 圖片預處理函數，將圖片大小調整為 4096x2160\n",
    "def preprocess_image(image, target_size=(4096, 2160)):\n",
    "    image = cv2.resize(image, target_size)  # 調整圖片大小\n",
    "    image = img_to_array(image) / 255.0  # 標準化\n",
    "    return image\n",
    "\n",
    "# 預處理訓練資料和測試資料\n",
    "X_train = np.array([preprocess_image(img) for img in X_train])\n",
    "X_test = np.array([preprocess_image(img) for img in X_test])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984ebbe7",
   "metadata": {},
   "source": [
    "# 構建自編碼器模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe72378d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_autoencoder(input_shape=(4096, 2160, 3)):\n",
    "    input_img = layers.Input(shape=input_shape)\n",
    "    # 編碼器部分\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    encoded = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "    # 解碼器部分\n",
    "    x = layers.Conv2DTranspose(128, (3, 3), activation='relu', padding='same')(encoded)\n",
    "    x = layers.UpSampling2D((2, 2))(x)\n",
    "    x = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)\n",
    "    x = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    decoded = layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    autoencoder = models.Model(input_img, decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    return autoencoder\n",
    "\n",
    "# 輸入形狀設置為 4096x2160\n",
    "input_shape = (4096, 2160, 3)\n",
    "autoencoder = build_autoencoder(input_shape)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b73dcd",
   "metadata": {},
   "source": [
    "# 訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205e99cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 自定義回呼函數，來實現進度條\n",
    "class TQDMProgressBar(Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epochs = self.params['epochs']\n",
    "        self.epochs_progress = tqdm(total=self.epochs, desc=\"Epochs\", position=0)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.epochs_progress.update(1)\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        self.epochs_progress.set_postfix(loss=logs['loss'], epoch=self.params['epochs'])\n",
    "\n",
    "# 使用自定義的回呼函數\n",
    "progress_bar = TQDMProgressBar()\n",
    "\n",
    "# 訓練模型並添加進度條\n",
    "autoencoder.fit(X_train, X_train, epochs=50, batch_size=32, shuffle=True, validation_data=(X_test, X_test), callbacks=[progress_bar])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b30c252",
   "metadata": {},
   "source": [
    "# 預測與保存結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aea1bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 進行預測\n",
    "predicted_images = autoencoder.predict(X_test)\n",
    "\n",
    "# 假設實際的鳳梨數量（Ground Truth）\n",
    "gt_pineapples = [len(label) for label in y_test]\n",
    "\n",
    "# 預測的鳳梨數量（可以根據模型輸出進行簡單估算）\n",
    "predicted_pineapples = [np.sum(pred > 0.5) for pred in predicted_images]  # 假設高於0.5的區域為鳳梨\n",
    "\n",
    "# 比較預測結果與真實結果\n",
    "print(\"Ground Truth vs Prediction:\")\n",
    "for i in range(len(gt_pineapples)):\n",
    "    print(f\"圖片 {i + 1}: 實際鳳梨數量={gt_pineapples[i]}, 預測鳳梨數量={predicted_pineapples[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cc664d",
   "metadata": {},
   "source": [
    "# 儲存結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539df0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# 儲存預測和 GT 的對比結果\n",
    "with open('predicted_vs_gt.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"圖片編號\", \"Ground Truth\", \"Prediction\"])\n",
    "    for i in range(len(gt_pineapples)):\n",
    "        writer.writerow([i + 1, gt_pineapples[i], predicted_pineapples[i]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
